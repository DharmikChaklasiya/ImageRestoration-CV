{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with base path: C:\\Users\\marti\\Documents\\computervision\\\n",
      "C:\\Users\\marti\\Documents\\computervision\\\n",
      "The directory 'C:\\Users\\marti\\Documents\\computervision\\integrals' already exists.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Import libraries section ##\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "from LFR_utils import read_poses_and_images,pose_to_virtualcamera, init_aos, init_window\n",
    "import LFR_utils as utils\n",
    "import pyaos\n",
    "import glm\n",
    "import glob\n",
    "import re\n",
    "\n",
    "\n",
    "## path to where the results will be stored \n",
    "\n",
    "user_name = os.getlogin()\n",
    "\n",
    "base_path = 'C:\\\\Users\\\\{}\\\\Documents\\\\computervision\\\\'.format(user_name)\n",
    "\n",
    "print(f\"Starting with base path: {base_path}\")\n",
    "\n",
    "Download_Location = base_path    ## Enter path to the directory where you want to save the results.\n",
    "\n",
    "Integral_Path = os.path.join(Download_Location,'integrals') # Note that your results will be saved to this integrals folder.\n",
    "\n",
    "print(f\"Results will be saved to: {Integral_Path}\")\n",
    "\n",
    "# Check if the directory already exists\n",
    "if not os.path.exists(Integral_Path):\n",
    "    os.mkdir(Integral_Path)\n",
    "else:\n",
    "    print(f\"The directory '{Integral_Path}' already exists.\")\n",
    "\n",
    "set_folder = base_path+r'\\\\ImageRestoration-CV\\\\LFR\\\\python'\n",
    "print(f\"Path to your LFR/python directory - it must be here: {set_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################Start the AOS Renderer###############################################################\n",
    "w,h,fovDegrees = 512, 512, 50 # # resolution and field of view. This should not be changed.\n",
    "render_fov = 50\n",
    "\n",
    "if 'window' not in locals() or window == None:                                    \n",
    "    window = pyaos.PyGlfwWindow( w, h, 'AOS' )  \n",
    "     \n",
    "aos = pyaos.PyAOS(w,h,fovDegrees) \n",
    "\n",
    "\n",
    "aos.loadDEM( os.path.join(set_folder,'zero_plane.obj'))\n",
    "\n",
    "####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################Create Poses for Initial Positions###############################################################\n",
    "\n",
    "# Below are certain functions required to convert the poses to a certain format to be compatabile with the AOS Renderer.\n",
    "\n",
    "def eul2rotm(theta) :\n",
    "    s_1 = math.sin(theta[0])\n",
    "    c_1 = math.cos(theta[0]) \n",
    "    s_2 = math.sin(theta[1]) \n",
    "    c_2 = math.cos(theta[1]) \n",
    "    s_3 = math.sin(theta[2]) \n",
    "    c_3 = math.cos(theta[2])\n",
    "    rotm = np.identity(3)\n",
    "    rotm[0,0] =  c_1*c_2\n",
    "    rotm[0,1] =  c_1*s_2*s_3 - s_1*c_3\n",
    "    rotm[0,2] =  c_1*s_2*c_3 + s_1*s_3\n",
    "\n",
    "    rotm[1,0] =  s_1*c_2\n",
    "    rotm[1,1] =  s_1*s_2*s_3 + c_1*c_3\n",
    "    rotm[1,2] =  s_1*s_2*c_3 - c_1*s_3\n",
    "\n",
    "    rotm[2,0] = -s_2\n",
    "    rotm[2,1] =  c_2*s_3\n",
    "    rotm[2,2] =  c_2*c_3        \n",
    "\n",
    "    return rotm\n",
    "\n",
    "def createviewmateuler(eulerang, camLocation):\n",
    "    \n",
    "    rotationmat = eul2rotm(eulerang)\n",
    "    translVec =  np.reshape((-camLocation @ rotationmat),(3,1))\n",
    "    conjoinedmat = (np.append(np.transpose(rotationmat), translVec, axis=1))\n",
    "    return conjoinedmat\n",
    "\n",
    "def divide_by_alpha(rimg2):\n",
    "        a = np.stack((rimg2[:,:,3],rimg2[:,:,3],rimg2[:,:,3]),axis=-1)\n",
    "        return rimg2[:,:,:3]/a\n",
    "\n",
    "def pose_to_virtualcamera(vpose ):\n",
    "    vp = glm.mat4(*np.array(vpose).transpose().flatten())\n",
    "    #vp = vpose.copy()\n",
    "    ivp = glm.inverse(glm.transpose(vp))\n",
    "    #ivp = glm.inverse(vpose)\n",
    "    Posvec = glm.vec3(ivp[3])\n",
    "    Upvec = glm.vec3(ivp[1])\n",
    "    FrontVec = glm.vec3(ivp[2])\n",
    "    lookAt = glm.lookAt(Posvec, Posvec + FrontVec, Upvec)\n",
    "    cameraviewarr = np.asarray(lookAt)\n",
    "    #print(cameraviewarr)\n",
    "    return cameraviewarr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing part : Part1\n",
      "Found 67 invalid image groups which will not be processed for Part1, image indices: [97, 458, 606, 804, 1154, 1268, 2075, 2285, 2514, 2639, 2685, 2712, 2773, 2845, 2891, 2972, 3092, 3258, 3265, 3316, 3336, 3387, 3442, 3482, 3572, 3576, 3591, 3684, 3908, 3967, 4001, 4011, 4045, 4046, 4054, 4127, 4156, 4168, 4172, 4244, 4280, 4424, 4428, 4430, 4440, 4491, 4559, 4581, 4642, 4694, 4727, 4827, 4866, 4904, 4966, 4989, 5059, 5065, 5069, 5092, 5205, 5206, 5217, 5222, 5257, 5274, 5423]\n",
      "Invalidity reason: Could not find ground truth file - Count: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing image to C:\\Users\\marti\\Documents\\computervision\\integrals\\Part1\\001607\\001607_03.png:  29%|██▉       | 1597/5429 [1:08:53<2:46:34,  2.61s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import shutil\n",
    "\n",
    "def copy_and_rename_file(src, new_name):\n",
    "    assert os.path.exists(src), f\"Could not find file {src}\"\n",
    "    os.makedirs(os.path.dirname(new_name), exist_ok=True)\n",
    "    shutil.copy(src, new_name)\n",
    "\n",
    "class ImageGroup:\n",
    "    def __init__(self, image_index):\n",
    "        assert image_index is not None\n",
    "        assert isinstance(image_index, int)\n",
    "        assert image_index >= 0\n",
    "        self.image_index = image_index\n",
    "        self.formatted_image_index = str(image_index).zfill(6)\n",
    "        self.filenames = []\n",
    "        self.base_output_path = None\n",
    "        self.original_ground_truth_file = None\n",
    "        self.new_ground_truth_file = None\n",
    "        self.original_parameter_file = None\n",
    "        self.new_parameter_file = None\n",
    "        self.valid = True\n",
    "        self.invalid_reason = None\n",
    "        self.invalid_reason_filenames = None\n",
    "\n",
    "    def add_filename(self, full_filename):\n",
    "        self.filenames.append(full_filename)\n",
    "\n",
    "    def _initialize_filenames(self, full_filename, base_output_path):\n",
    "        leading_digit = os.path.basename(full_filename).split('_')[0]\n",
    "        base_path = os.path.dirname(full_filename)\n",
    "        self.base_output_path = os.path.join(base_output_path, self.formatted_image_index)\n",
    "        self.original_ground_truth_file = os.path.join(base_path, f\"{leading_digit}_{self.image_index}_GT_pose_0_thermal.png\")\n",
    "        self.new_ground_truth_file = os.path.join(self.base_output_path, f\"{self.formatted_image_index}_gt.png\")\n",
    "        self.original_parameter_file = os.path.join(base_path, f\"{leading_digit}_{self.image_index}_Parameters.txt\")\n",
    "        self.new_parameter_file = os.path.join(self.base_output_path, f\"{self.formatted_image_index}_params.txt\")\n",
    "\n",
    "    def initialize_and_validate(self, base_output_path):\n",
    "        assert base_output_path is not None and isinstance(base_output_path, str)\n",
    "        self._initialize_filenames(self.filenames[0], base_output_path)\n",
    "        if not os.path.exists(self.original_ground_truth_file):\n",
    "            self.valid = False\n",
    "            self.invalid_reason = \"\" if self.invalid_reason is None else self.invalid_reason\n",
    "            self.invalid_reason += f\"Could not find ground truth file\"\n",
    "            self.invalid_reason_filenames = [] if self.invalid_reason_filenames is None else self.invalid_reason_filenames\n",
    "            self.invalid_reason_filenames.append(self.original_ground_truth_file)\n",
    "        if not os.path.exists(self.original_parameter_file):\n",
    "            self.valid = False\n",
    "            self.invalid_reason = \"\" if self.invalid_reason is None else self.invalid_reason\n",
    "            self.invalid_reason += f\"Could not find parameter file\"\n",
    "            self.invalid_reason_filenames = [] if self.invalid_reason_filenames is None else self.invalid_reason_filenames\n",
    "            self.invalid_reason_filenames.append(self.original_parameter_file)\n",
    "        if len(self.filenames) < 11:\n",
    "            self.valid = False\n",
    "            self.invalid_reason = \"\" if self.invalid_reason is None else self.invalid_reason\n",
    "            self.invalid_reason += f\"Expected 11 images but got less\"\n",
    "            self.invalid_reason_filenames = [] if self.invalid_reason_filenames is None else self.invalid_reason_filenames\n",
    "            self.invalid_reason_filenames.append(self.filenames)\n",
    "        if len(self.filenames) > 11:\n",
    "            self.valid = False\n",
    "            self.invalid_reason = \"\" if self.invalid_reason is None else self.invalid_reason\n",
    "            self.invalid_reason += f\"Expected 11 images but got more\"\n",
    "            self.invalid_reason_filenames = [] if self.invalid_reason_filenames is None else self.invalid_reason_filenames\n",
    "            self.invalid_reason_filenames.append(self.filenames)\n",
    "\n",
    "    def output_image_name(self, focal_stack_img_index):\n",
    "        formatted_focal_stack_img_index = str(focal_stack_img_index).zfill(2)\n",
    "        return os.path.join(self.base_output_path, f\"{self.formatted_image_index}_{formatted_focal_stack_img_index}.png\")\n",
    "\n",
    "\n",
    "########################## Below we generate the poses for rendering #####################################\n",
    "# This is based on how renderer is implemented. \n",
    "\n",
    "def load_filenames(base_path):\n",
    "    all_files = os.listdir(base_path)\n",
    "    file_dict = {}\n",
    "\n",
    "    # Regex to extract image_index and pose_index\n",
    "    file_pattern = re.compile(r\"([0123456789])_(\\d+)_pose_(\\d+)_thermal\\.png\")\n",
    "\n",
    "    for file in all_files:\n",
    "        match = file_pattern.match(file)\n",
    "        if match:\n",
    "            image_prefix = match.group(1)\n",
    "            image_index = match.group(2)\n",
    "            full_image_index = int(image_prefix + image_index)\n",
    "            if full_image_index not in file_dict:\n",
    "                file_dict[full_image_index] = ImageGroup(full_image_index)\n",
    "            file_dict[full_image_index].add_filename(os.path.join(base_path, file))\n",
    "    return file_dict\n",
    "\n",
    "def create_output_directory(base_output_path, part_name):\n",
    "    output_dir = os.path.join(base_output_path, part_name)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    return output_dir\n",
    "\n",
    "def create_integral_image(file_list, output_image_name, Focal_plane, progress_bar):\n",
    "\n",
    "    assert len(file_list) == 11, f\"Expected 11 images but got {len(file_list)}\"\n",
    "    Numberofimages = 11\n",
    "    # ref_loc is the reference location or the poses of the images. The poses are the same for the dataset and therefore only the images have to be replaced.\n",
    "    ref_loc = [[5,4,3,2,1,0,-1,-2,-3,-4,-5],[0,0,0,0,0,0,0,0,0,0,0]]   # These are the x and y positions of the images. It is of the form [[x_positions],[y_positions]]\n",
    "\n",
    "    altitude_list = [35,35,35,35,35,35,35,35,35,35,35] # [Z values which is the height]\n",
    "\n",
    "    center_index = 5  # this is important, this will be the pose index at which the integration should happen. For example if you have 5 images, lets say you want to integrate all 5 images to the second image position. Then your center_index is 1 as index starts from zero.\n",
    "\n",
    "    site_poses = []\n",
    "    for i in range(Numberofimages):\n",
    "        EastCentered = (ref_loc[0][i] - 0.0) #Get MeanEast and Set MeanEast\n",
    "        NorthCentered = (0.0 - ref_loc[1][i]) #Get MeanNorth and Set MeanNorth\n",
    "        M = createviewmateuler(np.array([0.0, 0.0, 0.0]),np.array( [ref_loc[0][i], ref_loc[1][i], - altitude_list[i]] ))\n",
    "        #print('m',M)\n",
    "        ViewMatrix = np.vstack((M, np.array([0.0,0.0,0.0,1.0],dtype=np.float32)))\n",
    "        #print(ViewMatrix)\n",
    "        camerapose = np.asarray(ViewMatrix.transpose(),dtype=np.float32)\n",
    "        #print(camerapose)\n",
    "        site_poses.append(camerapose)  # site_poses is a list now containing all the poses of all the images in a certain format that is accecpted by the renderer.\n",
    "        \n",
    "    imagelist = []\n",
    "\n",
    "    for file in file_list:\n",
    "        img = cv2.imread(file)\n",
    "        assert img is not None, f\"Could not read image {file}\"\n",
    "        imagelist.append(img)\n",
    "        \n",
    "    #############################Read the generated images from the simulator and store in a list ###############################################################\n",
    "        \n",
    "\n",
    "    aos.clearViews()   # Every time you call the renderer you should use this line to clear the previous views  \n",
    "    for i in range(len(imagelist)):\n",
    "            aos.addView(imagelist[i], site_poses[i], \"DEM BlobTrack\")  # Here we are adding images to the renderer one by one.\n",
    "    aos.setDEMTransform([0, 0, Focal_plane*-1]) #This is the focal plane. You can change this to any value between -5 to 5, above ground is negative\n",
    "\n",
    "    proj_RGBimg = aos.render(pose_to_virtualcamera(site_poses[center_index]), render_fov)\n",
    "    tmp_RGB = divide_by_alpha(proj_RGBimg)\n",
    "    progress_bar.set_description(\"Writing image to {}\".format(output_image_name))\n",
    "    cv2.imwrite(output_image_name, tmp_RGB)   # Final result. Check the integral result in the integrals folder.\n",
    "\n",
    "\n",
    "base_paths = [\"Part1\", \"Part1 2\", \"Part1 3\", \"Part2\", \"Part2 2\", \"Part2 3\"]\n",
    "base_output_path = Integral_Path\n",
    "\n",
    "for part_name in base_paths:\n",
    "    print(f\"Processing part : {part_name}\")\n",
    "    part_base_path = os.path.join(base_path, part_name)\n",
    "    output_path = create_output_directory(base_output_path, part_name)\n",
    "\n",
    "    file_dict = load_filenames(part_base_path)\n",
    "\n",
    "    image_idx_list = sorted(image_idx_list, key=lambda x: int(x))\n",
    "\n",
    "    invalid_img_groups = []\n",
    "    invalid_img_group_reasons = {}\n",
    "\n",
    "    for image_idx in image_idx_list:\n",
    "        img_group : ImageGroup = file_dict[image_idx]\n",
    "        img_group.initialize_and_validate(output_path)\n",
    "        if not img_group.valid:\n",
    "            invalid_img_groups.append(img_group)\n",
    "            if img_group.invalid_reason not in invalid_img_group_reasons:\n",
    "                invalid_img_group_reasons[img_group.invalid_reason] = 0\n",
    "            invalid_img_group_reasons[img_group.invalid_reason] += 1\n",
    "\n",
    "\n",
    "    print(f\"Found {len(invalid_img_groups)} invalid image groups which will not be processed for {part_name}, image indices: {[x.image_index for x in invalid_img_groups]}\")\n",
    "    for reason, count in invalid_img_group_reasons.items():\n",
    "        print(f\"Invalidity reason: {reason} - Count: {count}\")\n",
    "\n",
    "    image_idx_list_with_progress_bar = tqdm(image_idx_list, desc=f\"Processing images in {part_name}\")\n",
    "\n",
    "    for image_idx in image_idx_list_with_progress_bar:\n",
    "        img_group : ImageGroup = file_dict[image_idx]\n",
    "\n",
    "        if not img_group.valid:\n",
    "            continue\n",
    "\n",
    "        copy_and_rename_file(img_group.original_parameter_file, img_group.new_parameter_file)\n",
    "        copy_and_rename_file(img_group.original_ground_truth_file, img_group.new_ground_truth_file)\n",
    "\n",
    "        for focal_stack_img_index in range(0, 31) :\n",
    "            create_integral_image(img_group.filenames, img_group.output_image_name(focal_stack_img_index), focal_stack_img_index * 0.1, image_idx_list_with_progress_bar)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0546a8624a4a236bae0f9fea37c96b2936c9ad1821cd89b71f7783537db0568"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
